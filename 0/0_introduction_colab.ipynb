{"cells":[{"cell_type":"markdown","metadata":{"id":"u5-sJJLDXT2v"},"source":["# 概説\n","\n","《学修項目》\n","*   深層学習の基礎と事例\n","*   画像認識技術と適用事例\n","\n","《キーワード》\n","> 機械学習、深層学習、ニューラルネットワーク、Deep Neural Network、パラメータ学習、U-Net、DenseNet、Attention/Transformer、CNN、RNN、GAN、ImageNet、MNIST、CIFAR-10\n"]},{"cell_type":"markdown","metadata":{"id":"xngFmphdjt1j"},"source":["《参考文献，参考書籍》\n","*   [1] [東京大学MIセンター公開教材 「AI基礎：3-4 深層学習の基礎と展望」](http://www.mi.u-tokyo.ac.jp/pdf/3-4_dl_basic_and_future.pdf) [《利用条件CC BY-NC-SA》](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja)\n","*   [2] [東京大学MIセンター公開教材 「AI基礎：3-5 認識」](http://www.mi.u-tokyo.ac.jp/pdf/3-5_recognition.pdf) [《利用条件CC BY-NC-SA》](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja)"]},{"cell_type":"markdown","metadata":{"id":"RY5_bPJNQwxM"},"source":["## 1. はじめに\n","\n","近年、人工知能（AI）の中で、最も注目を集めているのが機械学習の一種である深層学習（Deep Learning）の技術であろう。ここで、機械学習とは、一般に、大量のデータを学習機に与えて学習させることにより、目的の出力を得る技術である。"]},{"cell_type":"markdown","source":["例えば、犬と猫の写真をどちらかに識別する問題の場合、学習機に犬と猫の写真画像を大量に与え、それと同時にその写真が犬か猫かの正解データを与えることにより（このような学習を教師つき学習と呼ぶ）、学習機に犬か猫かを識別する学習をさせる。"],"metadata":{"id":"ssZ2pnFpnUL9"}},{"cell_type":"markdown","source":["このようにして構築したモデルに、犬か猫の写真を与えると、そのどちらかに識別してくれるようになる。深層学習は、このような機械学習の1つであり、学習機は多層構造のニューラルネットワーク（人間の神経回路網を模倣したネットワーク）で構成されている。また、深層学習は、現在、医療、自動運転、自然言語処理、音声認識、データ解析など、様々な分野に適用されており、その有効性が示されている。"],"metadata":{"id":"4BZMuqhYnZEr"}},{"cell_type":"markdown","source":["## 2. 教材の構成\n","\n","そこで、本教材では、ニューラルネットワークを画像認識の分野に適用する下記事例について取り上げ、その手法や性能について言及する。\n","\n","*   ① 文字認識における曲線の屈曲度の判定\n","*   ② 楽譜の音符検出における記号判定\n","*   ③ MLPを用いた数字画像の識別\n","*   ④ CNNを用いた数字画像・写真画像の識別\n"],"metadata":{"id":"Nvwiwbm_msCM"}},{"cell_type":"markdown","source":["なお、従来のニューラルネットワークの学習では、画像から識別に有効であると考えられる特徴をあらかじめ抽出し、その特徴量をネットワークの入力に与えて学習する手法が用いられてきた。例えば、犬と猫の識別の場合、目の色が識別に大きく関わっていると開発者が判断した場合、目の色の特徴量を抽出して、それを学習に使用する、といった方式である。本教材では、①と②の事例がこの手法に該当する（ここでは、3層型の単純なニューラルネットワークを用いる）。"],"metadata":{"id":"F3XIVFPPndod"}},{"cell_type":"markdown","source":["また、③の事例では、機械学習プラットフォームであるTensorFlowを用いた数字画像識別の例を示す（ここでは、簡単のため、特別な特徴量抽出をせず、画像の輝度値そのものを入力として、数字画像の識別を行う例を挙げる）。\n","\n"],"metadata":{"id":"UeoWJ_tznhyF"}},{"cell_type":"markdown","source":["一方、④の事例では、現在よく使われている深層学習の1つであるCNN（Convolutional Neural Network：畳み込みニューラルネットワーク）を用いた事例を紹介する。ここでは、特徴抽出機能を包含するネットワークが構築できることを示す（例えば、犬と猫の識別の場合、開発者が目の色のような特徴をあらかじめ抽出して与えることなしに、その写真画像そのものをネットワークに与えて学習することができる）。ここで、現在の最新技術だけを紹介せず、旧来の手法①、②、③も紹介するのは、そこで使われているニューラルネットワークの学習技術が、最新技術の手法④にも使われているからである。"],"metadata":{"id":"qDuMyFwVnjtC"}},{"cell_type":"markdown","source":["## 3. 深層学習の基礎と事例 [1]"],"metadata":{"id":"CRnqfFKp9x0W"}},{"cell_type":"markdown","source":["### 3.1 深層学習の基礎、Neural Network、Deep Neural Network"],"metadata":{"id":"0I4SLjbdB5_C"}},{"cell_type":"markdown","source":["<figure>\n","<a href=\"http://www.mi.u-tokyo.ac.jp/pdf/3-4_dl_basic_and_future.pdf#page=4\"><img src='https://raw.githubusercontent.com/MDASH-shinshu/MDASH-T-IR/main/UTAI-text/3-4/JPEG/3-4_dl_basic_and_future_04.jpg' alt='深層学習の基礎' width='640' border='1'></a>\n","</figure>"],"metadata":{"id":"CjBA2u72CEt0"}},{"cell_type":"markdown","source":["<figure>\n","<a href=\"http://www.mi.u-tokyo.ac.jp/pdf/3-4_dl_basic_and_future.pdf#page=5\"><img src='https://raw.githubusercontent.com/MDASH-shinshu/MDASH-T-IR/main/UTAI-text/3-4/JPEG/3-4_dl_basic_and_future_05.jpg' alt='ニューラルネットワークの原理' width='640' border='1'></a>\n","</figure>"],"metadata":{"id":"gujfC_tVCk-A"}},{"cell_type":"markdown","source":["<figure>\n","<a href=\"http://www.mi.u-tokyo.ac.jp/pdf/3-4_dl_basic_and_future.pdf#page=10\"><img src='https://raw.githubusercontent.com/MDASH-shinshu/MDASH-T-IR/main/UTAI-text/3-4/JPEG/3-4_dl_basic_and_future_10.jpg' alt='Deep Neural Networkの構造' width='640' border='1'></a>\n","</figure>"],"metadata":{"id":"kqV_JYtaCv4c"}},{"cell_type":"markdown","source":["### 3.2 深層学習器のモデリング、応用タスク、認識精度の向上"],"metadata":{"id":"yQcMsR8iC-Hd"}},{"cell_type":"markdown","source":["<figure>\n","<a href=\"http://www.mi.u-tokyo.ac.jp/pdf/3-4_dl_basic_and_future.pdf#page=11\"><img src='https://raw.githubusercontent.com/MDASH-shinshu/MDASH-T-IR/main/UTAI-text/3-4/JPEG/3-4_dl_basic_and_future_11.jpg' alt='Deep Neural Network：柔軟なモデリング' width='640' border='1'></a>\n","</figure>"],"metadata":{"id":"KFH62SolDE_R"}},{"cell_type":"markdown","source":["<figure>\n","<a href=\"http://www.mi.u-tokyo.ac.jp/pdf/3-4_dl_basic_and_future.pdf#page=12\"><img src='https://raw.githubusercontent.com/MDASH-shinshu/MDASH-T-IR/main/UTAI-text/3-4/JPEG/3-4_dl_basic_and_future_12.jpg' alt='Deep Neural Network：応用タスク' width='640' border='1'></a>\n","</figure>"],"metadata":{"id":"7COH73cBDreC"}},{"cell_type":"markdown","source":["<figure>\n","<a href=\"http://www.mi.u-tokyo.ac.jp/pdf/3-4_dl_basic_and_future.pdf#page=13\"><img src='https://raw.githubusercontent.com/MDASH-shinshu/MDASH-T-IR/main/UTAI-text/3-4/JPEG/3-4_dl_basic_and_future_13.jpg' alt='Deep Neural Network：認識精度の向上' width='640' border='1'></a>\n","</figure>"],"metadata":{"id":"TjefyhvJDzzu"}},{"cell_type":"markdown","source":["### 3.3 物体検出、マスキング、画像生成の例"],"metadata":{"id":"2MTINBM3EHB4"}},{"cell_type":"markdown","source":["<figure>\n","<a href=\"http://www.mi.u-tokyo.ac.jp/pdf/3-4_dl_basic_and_future.pdf#page=22\"><img src='https://raw.githubusercontent.com/MDASH-shinshu/MDASH-T-IR/main/UTAI-text/3-4/JPEG/3-4_dl_basic_and_future_22.jpg' alt='事例：物体検出' width='640' border='1'></a>\n","</figure>"],"metadata":{"id":"WqsBzEpjEZv5"}},{"cell_type":"markdown","source":["<figure>\n","<a href=\"http://www.mi.u-tokyo.ac.jp/pdf/3-4_dl_basic_and_future.pdf#page=23\"><img src='https://raw.githubusercontent.com/MDASH-shinshu/MDASH-T-IR/main/UTAI-text/3-4/JPEG/3-4_dl_basic_and_future_23.jpg' alt='事例：マスキング' width='640' border='1'></a>\n","</figure>"],"metadata":{"id":"ryaH0fHrEluV"}},{"cell_type":"markdown","source":["<figure>\n","<a href=\"http://www.mi.u-tokyo.ac.jp/pdf/3-4_dl_basic_and_future.pdf#page=24\"><img src='https://raw.githubusercontent.com/MDASH-shinshu/MDASH-T-IR/main/UTAI-text/3-4/JPEG/3-4_dl_basic_and_future_24.jpg' alt='事例：画像生成' width='640' border='1'></a>\n","</figure>"],"metadata":{"id":"psee5kMfEqT1"}},{"cell_type":"markdown","source":["## 4. 大規模データセットを用いた深層学習器、適用事例 [2]"],"metadata":{"id":"9Jgj7b0z-BjT"}},{"cell_type":"markdown","source":["### 4.1 大規模データセットを用いた学習、認識精度向上"],"metadata":{"id":"HytvlgQlGbio"}},{"cell_type":"markdown","source":["<figure>\n","<a href=\"http://www.mi.u-tokyo.ac.jp/pdf/3-5_recognition.pdf#page=49\"><img src='https://raw.githubusercontent.com/MDASH-shinshu/MDASH-T-IR/main/UTAI-text/3-5/JPEG/3-5_recognition_49.jpg' alt='深層学習による画像認識' width='640' border='1'></a>\n","</figure>"],"metadata":{"id":"y09JX2GpFd8O"}},{"cell_type":"markdown","source":["<figure>\n","<a href=\"http://www.mi.u-tokyo.ac.jp/pdf/3-5_recognition.pdf#page=50\"><img src='https://raw.githubusercontent.com/MDASH-shinshu/MDASH-T-IR/main/UTAI-text/3-5/JPEG/3-5_recognition_50.jpg' alt='物体認識精度の向上' width='640' border='1'></a>\n","</figure>"],"metadata":{"id":"RUP3XrjFGA7t"}},{"cell_type":"markdown","source":["<figure>\n","<a href=\"http://www.mi.u-tokyo.ac.jp/pdf/3-5_recognition.pdf#page=55\"><img src='https://raw.githubusercontent.com/MDASH-shinshu/MDASH-T-IR/main/UTAI-text/3-5/JPEG/3-5_recognition_55.jpg' alt='深層学習の革新性' width='640' border='1'></a>\n","</figure>"],"metadata":{"id":"SI-NGHuHGJoK"}},{"cell_type":"markdown","source":["### 4.2 画像認識の活用事例"],"metadata":{"id":"K5turkFuGrna"}},{"cell_type":"markdown","source":["<figure>\n","<a href=\"http://www.mi.u-tokyo.ac.jp/pdf/3-5_recognition.pdf#page=13\"><img src='https://raw.githubusercontent.com/MDASH-shinshu/MDASH-T-IR/main/UTAI-text/3-5/JPEG/3-5_recognition_13.jpg' alt='画像認識：顔領域検出' width='640' border='1'></a>\n","</figure>\n","\n","*   [ref. (2020/4/6): Wikimedia commons: File:Kasahara Saitama Kasahara Jinjo Elementary School 1920 1.jpg パブリックドメイン](https://ja.wikipedia.org/wiki/%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB:Kasahara_Saitama_Kasahara_Jinjo_Elementary_School_1920_1.jpg)"],"metadata":{"id":"nsLMaf6HG1N7"}},{"cell_type":"markdown","source":["<figure>\n","<a href=\"http://www.mi.u-tokyo.ac.jp/pdf/3-5_recognition.pdf#page=14\"><img src='https://raw.githubusercontent.com/MDASH-shinshu/MDASH-T-IR/main/UTAI-text/3-5/JPEG/3-5_recognition_14.jpg' alt='画像認識：手書き文字認識' width='640' border='1'></a>\n","</figure>\n","\n","*   [ref. (2020/4/6): THE MNIST DATABASE of handwritten digits](http://yann.lecun.com/exdb/mnist/)\n","*   [Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998](https://www.researchgate.net/publication/2985446_Gradient-Based_Learning_Applied_to_Document_Recognition)"],"metadata":{"id":"YYpCjijrHUfh"}},{"cell_type":"markdown","source":["<figure>\n","<a href=\"http://www.mi.u-tokyo.ac.jp/pdf/3-5_recognition.pdf#page=15\"><img src='https://raw.githubusercontent.com/MDASH-shinshu/MDASH-T-IR/main/UTAI-text/3-5/JPEG/3-5_recognition_15.jpg' alt='画像認識：一般物体検出' width='640' border='1'></a>\n","</figure>\n","\n","*   [ref. (2020/04/06): The CIFAR-10 dataset](http://www.cs.toronto.edu/%7Ekriz/cifar.html)\n"],"metadata":{"id":"nNlhgNWkIHDS"}},{"cell_type":"markdown","source":["<figure>\n","<a href=\"http://www.mi.u-tokyo.ac.jp/pdf/3-5_recognition.pdf#page=21\"><img src='https://raw.githubusercontent.com/MDASH-shinshu/MDASH-T-IR/main/UTAI-text/3-5/JPEG/3-5_recognition_21.jpg' alt='画像認識：OpenPose' width='640' border='1'></a>\n","</figure>\n","\n","*   [ref. (2020/4/6) Zhe Cao, Tomas Simon, Shih-En Wei, Yaser Sheikh, “Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields”, CVPR2017,](https://github.com/CMU-Perceptual-Computing-Lab/openpose)\n"],"metadata":{"id":"QWNiG2nqIdar"}},{"cell_type":"markdown","metadata":{"id":"DHQkZ7WJJOXd"},"source":["# memo"]}],"metadata":{"celltoolbar":"Slideshow","colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":0}